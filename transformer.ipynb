{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79a79dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sentencepiece as sp\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d13d8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge_score in c:\\users\\ncs\\anaconda3\\envs\\env_ml_2\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: sacrebleu in c:\\users\\ncs\\anaconda3\\envs\\env_ml_2\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: absl-py in c:\\users\\ncs\\anaconda3\\envs\\env_ml_2\\lib\\site-packages (from rouge_score) (2.3.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\ncs\\anaconda3\\envs\\env_ml_2\\lib\\site-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ncs\\anaconda3\\envs\\env_ml_2\\lib\\site-packages (from rouge_score) (2.0.1)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\ncs\\anaconda3\\envs\\env_ml_2\\lib\\site-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: portalocker in c:\\users\\ncs\\anaconda3\\envs\\env_ml_2\\lib\\site-packages (from sacrebleu) (3.2.0)\n",
      "Requirement already satisfied: regex in c:\\users\\ncs\\anaconda3\\envs\\env_ml_2\\lib\\site-packages (from sacrebleu) (2025.9.18)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in c:\\users\\ncs\\anaconda3\\envs\\env_ml_2\\lib\\site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ncs\\anaconda3\\envs\\env_ml_2\\lib\\site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in c:\\users\\ncs\\anaconda3\\envs\\env_ml_2\\lib\\site-packages (from sacrebleu) (6.0.2)\n",
      "Requirement already satisfied: click in c:\\users\\ncs\\anaconda3\\envs\\env_ml_2\\lib\\site-packages (from nltk->rouge_score) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\ncs\\anaconda3\\envs\\env_ml_2\\lib\\site-packages (from nltk->rouge_score) (1.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ncs\\anaconda3\\envs\\env_ml_2\\lib\\site-packages (from nltk->rouge_score) (4.67.1)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\ncs\\anaconda3\\envs\\env_ml_2\\lib\\site-packages (from portalocker->sacrebleu) (311)\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6de9a281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu.metrics import BLEU, CHRF\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7144dde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "torch.set_default_device(device)\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8e16e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = sp.SentencePieceProcessor()\n",
    "tokenizer.Load('D:/Workspace/PYTHON/NLP/Project2/tokenizer/unigram/unigram_tokenizer.model')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8bd517b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 256\n",
      "PAD ID: 0\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = tokenizer.get_piece_size()\n",
    "PAD_ID = tokenizer.piece_to_id('<pad>')\n",
    "    \n",
    "print(f\"Vocabulary size: {VOCAB_SIZE}\")\n",
    "print(f\"PAD ID: {PAD_ID}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d4036f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('D:/Workspace/PYTHON/NLP/Project2/Data/span_corruption_dataset.pt')\n",
    "input_ids = data['input_ids']\n",
    "target_ids = data['target_ids']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3954e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 8197\n",
      "Validation samples: 2050\n"
     ]
    }
   ],
   "source": [
    "split_idx = int(len(input_ids) * 0.8)\n",
    "train_input = input_ids[:split_idx]\n",
    "train_target = target_ids[:split_idx]\n",
    "val_input = input_ids[split_idx:]\n",
    "val_target = target_ids[split_idx:]\n",
    "\n",
    "print(f\"Training samples: {len(train_input)}\")\n",
    "print(f\"Validation samples: {len(val_input)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cacef9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrduDataset(Dataset):\n",
    "    def __init__(self,input_ids,target_ids):\n",
    "        super().__init__()\n",
    "        self.input_ids = input_ids\n",
    "        self.target_ids = target_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.input_ids[idx], dtype=torch.long),\n",
    "            'target_ids': torch.tensor(self.target_ids[idx], dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    input_ids = [item['input_ids'] for item in batch]\n",
    "    target_ids = [item['target_ids'] for item in batch]\n",
    "    \n",
    "    input_ids=nn.utils.rnn.pad_sequence(input_ids,batch_first=True,padding_value=PAD_ID)\n",
    "    target_ids=nn.utils.rnn.pad_sequence(target_ids,batch_first=True,padding_value=PAD_ID)\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'target_ids': target_ids\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21a9e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = UrduDataset(train_input, train_target)\n",
    "val_dataset = UrduDataset(val_input, val_target)\n",
    "    \n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2446679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccd3e2b5",
   "metadata": {},
   "source": [
    "# --------------------TRANSFORMER CODE--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baf13064",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_positional_encoding(max_seq_len, dm):\n",
    "    pos=torch.arange(max_seq_len).unsqueeze(1)               \n",
    "    denom = 10000 ** (2 * torch.arange(0, dm//2)/ dm)\n",
    "    angles = pos / denom\n",
    "    PE = torch.zeros(max_seq_len, dm)\n",
    "    PE[:, 0::2] = torch.sin(angles)         \n",
    "    PE[:, 1::2] = torch.cos(angles)  \n",
    "    return PE    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2eaec83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50])\n",
      "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
      "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
      "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
      "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
      "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
      "        [ 8.4147e-01,  5.4030e-01,  6.3795e-01,  7.7008e-01,  4.6056e-01,\n",
      "          8.8763e-01,  3.2511e-01,  9.4568e-01,  2.2709e-01,  9.7387e-01,\n",
      "          1.5783e-01,  9.8747e-01,  1.0943e-01,  9.9399e-01,  7.5785e-02,\n",
      "          9.9712e-01,  5.2457e-02,  9.9862e-01,  3.6300e-02,  9.9934e-01,\n",
      "          2.5116e-02,  9.9968e-01,  1.7377e-02,  9.9985e-01,  1.2022e-02,\n",
      "          9.9993e-01,  8.3175e-03,  9.9997e-01,  5.7544e-03,  9.9998e-01,\n",
      "          3.9811e-03,  9.9999e-01,  2.7542e-03,  1.0000e+00,  1.9055e-03,\n",
      "          1.0000e+00,  1.3183e-03,  1.0000e+00,  9.1201e-04,  1.0000e+00,\n",
      "          6.3096e-04,  1.0000e+00,  4.3652e-04,  1.0000e+00,  3.0200e-04,\n",
      "          1.0000e+00,  2.0893e-04,  1.0000e+00,  1.4454e-04,  1.0000e+00],\n",
      "        [ 9.0930e-01, -4.1615e-01,  9.8254e-01,  1.8604e-01,  8.1762e-01,\n",
      "          5.7576e-01,  6.1490e-01,  7.8860e-01,  4.4231e-01,  8.9686e-01,\n",
      "          3.1170e-01,  9.5018e-01,  2.1754e-01,  9.7605e-01,  1.5113e-01,\n",
      "          9.8851e-01,  1.0477e-01,  9.9450e-01,  7.2552e-02,  9.9736e-01,\n",
      "          5.0217e-02,  9.9874e-01,  3.4749e-02,  9.9940e-01,  2.4043e-02,\n",
      "          9.9971e-01,  1.6635e-02,  9.9986e-01,  1.1509e-02,  9.9993e-01,\n",
      "          7.9621e-03,  9.9997e-01,  5.5084e-03,  9.9998e-01,  3.8109e-03,\n",
      "          9.9999e-01,  2.6365e-03,  1.0000e+00,  1.8240e-03,  1.0000e+00,\n",
      "          1.2619e-03,  1.0000e+00,  8.7303e-04,  1.0000e+00,  6.0399e-04,\n",
      "          1.0000e+00,  4.1786e-04,  1.0000e+00,  2.8909e-04,  1.0000e+00],\n",
      "        [ 1.4112e-01, -9.8999e-01,  8.7532e-01, -4.8354e-01,  9.9091e-01,\n",
      "          1.3450e-01,  8.3788e-01,  5.4585e-01,  6.3442e-01,  7.7299e-01,\n",
      "          4.5775e-01,  8.8908e-01,  3.2304e-01,  9.4638e-01,  2.2561e-01,\n",
      "          9.7422e-01,  1.5679e-01,  9.8763e-01,  1.0871e-01,  9.9407e-01,\n",
      "          7.5285e-02,  9.9716e-01,  5.2110e-02,  9.9864e-01,  3.6060e-02,\n",
      "          9.9935e-01,  2.4950e-02,  9.9969e-01,  1.7262e-02,  9.9985e-01,\n",
      "          1.1943e-02,  9.9993e-01,  8.2626e-03,  9.9997e-01,  5.7164e-03,\n",
      "          9.9998e-01,  3.9548e-03,  9.9999e-01,  2.7360e-03,  1.0000e+00,\n",
      "          1.8929e-03,  1.0000e+00,  1.3095e-03,  1.0000e+00,  9.0599e-04,\n",
      "          1.0000e+00,  6.2679e-04,  1.0000e+00,  4.3363e-04,  1.0000e+00],\n",
      "        [-7.5680e-01, -6.5364e-01,  3.6559e-01, -9.3078e-01,  9.4151e-01,\n",
      "         -3.3700e-01,  9.6983e-01,  2.4379e-01,  7.9338e-01,  6.0872e-01,\n",
      "          5.9234e-01,  8.0569e-01,  4.2466e-01,  9.0535e-01,  2.9880e-01,\n",
      "          9.5432e-01,  2.0838e-01,  9.7805e-01,  1.4472e-01,  9.8947e-01,\n",
      "          1.0031e-01,  9.9496e-01,  6.9456e-02,  9.9758e-01,  4.8072e-02,\n",
      "          9.9884e-01,  3.3264e-02,  9.9945e-01,  2.3016e-02,  9.9974e-01,\n",
      "          1.5924e-02,  9.9987e-01,  1.1017e-02,  9.9994e-01,  7.6218e-03,\n",
      "          9.9997e-01,  5.2730e-03,  9.9999e-01,  3.6480e-03,  9.9999e-01,\n",
      "          2.5238e-03,  1.0000e+00,  1.7461e-03,  1.0000e+00,  1.2080e-03,\n",
      "          1.0000e+00,  8.3572e-04,  1.0000e+00,  5.7818e-04,  1.0000e+00],\n",
      "        [-9.5892e-01,  2.8366e-01, -3.1225e-01, -9.5000e-01,  6.8050e-01,\n",
      "         -7.3275e-01,  9.9640e-01, -8.4758e-02,  9.1089e-01,  4.1265e-01,\n",
      "          7.1207e-01,  7.0211e-01,  5.2119e-01,  8.5344e-01,  3.7026e-01,\n",
      "          9.2893e-01,  2.5940e-01,  9.6577e-01,  1.8054e-01,  9.8357e-01,\n",
      "          1.2526e-01,  9.9212e-01,  8.6781e-02,  9.9623e-01,  6.0077e-02,\n",
      "          9.9819e-01,  4.1576e-02,  9.9914e-01,  2.8768e-02,  9.9959e-01,\n",
      "          1.9904e-02,  9.9980e-01,  1.3771e-02,  9.9991e-01,  9.5272e-03,\n",
      "          9.9995e-01,  6.5912e-03,  9.9998e-01,  4.5600e-03,  9.9999e-01,\n",
      "          3.1548e-03,  1.0000e+00,  2.1826e-03,  1.0000e+00,  1.5100e-03,\n",
      "          1.0000e+00,  1.0446e-03,  1.0000e+00,  7.2272e-04,  1.0000e+00],\n",
      "        [-2.7942e-01,  9.6017e-01, -8.4651e-01, -5.3237e-01,  2.6655e-01,\n",
      "         -9.6382e-01,  9.1472e-01, -4.0410e-01,  9.8080e-01,  1.9502e-01,\n",
      "          8.1396e-01,  5.8092e-01,  6.1145e-01,  7.9129e-01,  4.3959e-01,\n",
      "          8.9820e-01,  3.0971e-01,  9.5083e-01,  2.1613e-01,  9.7637e-01,\n",
      "          1.5014e-01,  9.8866e-01,  1.0408e-01,  9.9457e-01,  7.2073e-02,\n",
      "          9.9740e-01,  4.9885e-02,  9.9875e-01,  3.4520e-02,  9.9940e-01,\n",
      "          2.3884e-02,  9.9971e-01,  1.6525e-02,  9.9986e-01,  1.1433e-02,\n",
      "          9.9993e-01,  7.9095e-03,  9.9997e-01,  5.4720e-03,  9.9999e-01,\n",
      "          3.7857e-03,  9.9999e-01,  2.6191e-03,  1.0000e+00,  1.8120e-03,\n",
      "          1.0000e+00,  1.2536e-03,  1.0000e+00,  8.6726e-04,  1.0000e+00],\n",
      "        [ 6.5699e-01,  7.5390e-01, -9.9151e-01,  1.3006e-01, -2.0730e-01,\n",
      "         -9.7828e-01,  7.3365e-01, -6.7953e-01,  9.9946e-01, -3.2805e-02,\n",
      "          8.9544e-01,  4.4518e-01,  6.9436e-01,  7.1962e-01,  5.0640e-01,\n",
      "          8.6230e-01,  3.5916e-01,  9.3328e-01,  2.5143e-01,  9.6788e-01,\n",
      "          1.7493e-01,  9.8458e-01,  1.2135e-01,  9.9261e-01,  8.4059e-02,\n",
      "          9.9646e-01,  5.8191e-02,  9.9831e-01,  4.0270e-02,  9.9919e-01,\n",
      "          2.7864e-02,  9.9961e-01,  1.9278e-02,  9.9981e-01,  1.3338e-02,\n",
      "          9.9991e-01,  9.2277e-03,  9.9996e-01,  6.3840e-03,  9.9998e-01,\n",
      "          4.4167e-03,  9.9999e-01,  3.0556e-03,  1.0000e+00,  2.1140e-03,\n",
      "          1.0000e+00,  1.4625e-03,  1.0000e+00,  1.0118e-03,  1.0000e+00],\n",
      "        [ 9.8936e-01, -1.4550e-01, -6.8057e-01,  7.3269e-01, -6.3457e-01,\n",
      "         -7.7287e-01,  4.7287e-01, -8.8113e-01,  9.6590e-01, -2.5891e-01,\n",
      "          9.5448e-01,  2.9827e-01,  7.6894e-01,  6.3932e-01,  5.7029e-01,\n",
      "          8.2144e-01,  4.0762e-01,  9.1315e-01,  2.8640e-01,  9.5811e-01,\n",
      "          1.9960e-01,  9.7988e-01,  1.3858e-01,  9.9035e-01,  9.6033e-02,\n",
      "          9.9538e-01,  6.6492e-02,  9.9779e-01,  4.6019e-02,  9.9894e-01,\n",
      "          3.1843e-02,  9.9949e-01,  2.2032e-02,  9.9976e-01,  1.5243e-02,\n",
      "          9.9988e-01,  1.0546e-02,  9.9994e-01,  7.2960e-03,  9.9997e-01,\n",
      "          5.0476e-03,  9.9999e-01,  3.4921e-03,  9.9999e-01,  2.4160e-03,\n",
      "          1.0000e+00,  1.6714e-03,  1.0000e+00,  1.1564e-03,  1.0000e+00],\n",
      "        [ 4.1212e-01, -9.1113e-01, -5.6676e-02,  9.9839e-01, -9.1921e-01,\n",
      "         -3.9376e-01,  1.6071e-01, -9.8700e-01,  8.8187e-01, -4.7149e-01,\n",
      "          9.8959e-01,  1.4389e-01,  8.3428e-01,  5.5134e-01,  6.3091e-01,\n",
      "          7.7586e-01,  4.5496e-01,  8.9051e-01,  3.2099e-01,  9.4708e-01,\n",
      "          2.2415e-01,  9.7455e-01,  1.5577e-01,  9.8779e-01,  1.0799e-01,\n",
      "          9.9415e-01,  7.4789e-02,  9.9720e-01,  5.1766e-02,  9.9866e-01,\n",
      "          3.5822e-02,  9.9936e-01,  2.4786e-02,  9.9969e-01,  1.7148e-02,\n",
      "          9.9985e-01,  1.1864e-02,  9.9993e-01,  8.2080e-03,  9.9997e-01,\n",
      "          5.6786e-03,  9.9998e-01,  3.9286e-03,  9.9999e-01,  2.7180e-03,\n",
      "          1.0000e+00,  1.8804e-03,  1.0000e+00,  1.3009e-03,  1.0000e+00],\n",
      "        [-5.4402e-01, -8.3907e-01,  5.9328e-01,  8.0500e-01, -9.9727e-01,\n",
      "          7.3845e-02, -1.6891e-01, -9.8563e-01,  7.5176e-01, -6.5944e-01,\n",
      "          9.9990e-01, -1.4096e-02,  8.8960e-01,  4.5673e-01,  6.8789e-01,\n",
      "          7.2582e-01,  5.0105e-01,  8.6542e-01,  3.5515e-01,  9.3481e-01,\n",
      "          2.4856e-01,  9.6862e-01,  1.7291e-01,  9.8494e-01,  1.1994e-01,\n",
      "          9.9278e-01,  8.3081e-02,  9.9654e-01,  5.7512e-02,  9.9834e-01,\n",
      "          3.9800e-02,  9.9921e-01,  2.7539e-02,  9.9962e-01,  1.9053e-02,\n",
      "          9.9982e-01,  1.3182e-02,  9.9991e-01,  9.1200e-03,  9.9996e-01,\n",
      "          6.3095e-03,  9.9998e-01,  4.3651e-03,  9.9999e-01,  3.0199e-03,\n",
      "          1.0000e+00,  2.0893e-03,  1.0000e+00,  1.4454e-03,  1.0000e+00],\n",
      "        [-9.9999e-01,  4.4257e-03,  9.7042e-01,  2.4143e-01, -8.5119e-01,\n",
      "          5.2485e-01, -4.8017e-01, -8.7717e-01,  5.8237e-01, -8.1293e-01,\n",
      "          9.8514e-01, -1.7173e-01,  9.3424e-01,  3.5664e-01,  7.4092e-01,\n",
      "          6.7160e-01,  5.4575e-01,  8.3795e-01,  3.8885e-01,  9.2130e-01,\n",
      "          2.7281e-01,  9.6207e-01,  1.9000e-01,  9.8178e-01,  1.3186e-01,\n",
      "          9.9127e-01,  9.1366e-02,  9.9582e-01,  6.3256e-02,  9.9800e-01,\n",
      "          4.3778e-02,  9.9904e-01,  3.0292e-02,  9.9954e-01,  2.0959e-02,\n",
      "          9.9978e-01,  1.4500e-02,  9.9989e-01,  1.0032e-02,  9.9995e-01,\n",
      "          6.9405e-03,  9.9998e-01,  4.8017e-03,  9.9999e-01,  3.3219e-03,\n",
      "          9.9999e-01,  2.2982e-03,  1.0000e+00,  1.5900e-03,  1.0000e+00],\n",
      "        [-5.3657e-01,  8.4385e-01,  9.0132e-01, -4.3316e-01, -5.1381e-01,\n",
      "          8.5790e-01, -7.3927e-01, -6.7341e-01,  3.8255e-01, -9.2394e-01,\n",
      "          9.4569e-01, -3.2506e-01,  9.6766e-01,  2.5227e-01,  7.8968e-01,\n",
      "          6.1351e-01,  5.8896e-01,  8.0816e-01,  4.2204e-01,  9.0658e-01,\n",
      "          2.9688e-01,  9.5491e-01,  2.0703e-01,  9.7834e-01,  1.4377e-01,\n",
      "          9.8961e-01,  9.9646e-02,  9.9502e-01,  6.8998e-02,  9.9762e-01,\n",
      "          4.7755e-02,  9.9886e-01,  3.3045e-02,  9.9945e-01,  2.2864e-02,\n",
      "          9.9974e-01,  1.5818e-02,  9.9987e-01,  1.0944e-02,  9.9994e-01,\n",
      "          7.5714e-03,  9.9997e-01,  5.2382e-03,  9.9999e-01,  3.6239e-03,\n",
      "          9.9999e-01,  2.5072e-03,  1.0000e+00,  1.7345e-03,  1.0000e+00],\n",
      "        [ 4.2017e-01,  9.0745e-01,  4.1776e-01, -9.0856e-01, -6.0956e-02,\n",
      "          9.9814e-01, -9.1804e-01, -3.9648e-01,  1.6274e-01, -9.8667e-01,\n",
      "          8.8254e-01, -4.7024e-01,  9.8945e-01,  1.4486e-01,  8.3391e-01,\n",
      "          5.5190e-01,  6.3054e-01,  7.7616e-01,  4.5467e-01,  8.9066e-01,\n",
      "          3.2077e-01,  9.4716e-01,  2.2400e-01,  9.7459e-01,  1.5566e-01,\n",
      "          9.8781e-01,  1.0792e-01,  9.9416e-01,  7.4737e-02,  9.9720e-01,\n",
      "          5.1731e-02,  9.9866e-01,  3.5797e-02,  9.9936e-01,  2.4768e-02,\n",
      "          9.9969e-01,  1.7136e-02,  9.9985e-01,  1.1856e-02,  9.9993e-01,\n",
      "          8.2024e-03,  9.9997e-01,  5.6747e-03,  9.9998e-01,  3.9259e-03,\n",
      "          9.9999e-01,  2.7161e-03,  1.0000e+00,  1.8791e-03,  1.0000e+00],\n",
      "        [ 9.9061e-01,  1.3674e-01, -2.5791e-01, -9.6617e-01,  4.0560e-01,\n",
      "          9.1405e-01, -9.9707e-01, -7.6478e-02, -6.5575e-02, -9.9785e-01,\n",
      "          7.9726e-01, -6.0364e-01,  9.9936e-01,  3.5719e-02,  8.7334e-01,\n",
      "          4.8712e-01,  6.7039e-01,  7.4201e-01,  4.8670e-01,  8.7357e-01,\n",
      "          3.4446e-01,  9.3880e-01,  2.4090e-01,  9.7055e-01,  1.6752e-01,\n",
      "          9.8587e-01,  1.1618e-01,  9.9323e-01,  8.0474e-02,  9.9676e-01,\n",
      "          5.5706e-02,  9.9845e-01,  3.8550e-02,  9.9926e-01,  2.6673e-02,\n",
      "          9.9964e-01,  1.8455e-02,  9.9983e-01,  1.2768e-02,  9.9992e-01,\n",
      "          8.8333e-03,  9.9996e-01,  6.1112e-03,  9.9998e-01,  4.2279e-03,\n",
      "          9.9999e-01,  2.9250e-03,  1.0000e+00,  2.0236e-03,  1.0000e+00],\n",
      "        [ 6.5029e-01, -7.5969e-01, -8.1498e-01, -5.7950e-01,  7.8100e-01,\n",
      "          6.2453e-01, -9.6777e-01,  2.5184e-01, -2.9046e-01, -9.5689e-01,\n",
      "          6.9200e-01, -7.2190e-01,  9.9727e-01, -7.3854e-02,  9.0774e-01,\n",
      "          4.1953e-01,  7.0839e-01,  7.0582e-01,  5.1809e-01,  8.5533e-01,\n",
      "          3.6793e-01,  9.2985e-01,  2.5773e-01,  9.6622e-01,  1.7936e-01,\n",
      "          9.8378e-01,  1.2444e-01,  9.9223e-01,  8.6209e-02,  9.9628e-01,\n",
      "          5.9681e-02,  9.9822e-01,  4.1302e-02,  9.9915e-01,  2.8578e-02,\n",
      "          9.9959e-01,  1.9773e-02,  9.9980e-01,  1.3680e-02,  9.9991e-01,\n",
      "          9.4642e-03,  9.9996e-01,  6.5477e-03,  9.9998e-01,  4.5299e-03,\n",
      "          9.9999e-01,  3.1339e-03,  1.0000e+00,  2.1682e-03,  1.0000e+00],\n",
      "        [-2.8790e-01, -9.5766e-01, -9.9728e-01,  7.3655e-02,  9.8087e-01,\n",
      "          1.9465e-01, -8.3332e-01,  5.5279e-01, -5.0017e-01, -8.6593e-01,\n",
      "          5.6939e-01, -8.2207e-01,  9.8320e-01, -1.8254e-01,  9.3692e-01,\n",
      "          3.4953e-01,  7.4444e-01,  6.6769e-01,  5.4880e-01,  8.3596e-01,\n",
      "          3.9117e-01,  9.2032e-01,  2.7448e-01,  9.6159e-01,  1.9118e-01,\n",
      "          9.8156e-01,  1.3269e-01,  9.9116e-01,  9.1940e-02,  9.9576e-01,\n",
      "          6.3654e-02,  9.9797e-01,  4.4053e-02,  9.9903e-01,  3.0483e-02,\n",
      "          9.9954e-01,  2.1091e-02,  9.9978e-01,  1.4592e-02,  9.9989e-01,\n",
      "          1.0095e-02,  9.9995e-01,  6.9842e-03,  9.9998e-01,  4.8319e-03,\n",
      "          9.9999e-01,  3.3429e-03,  9.9999e-01,  2.3127e-03,  1.0000e+00],\n",
      "        [-9.6140e-01, -2.7516e-01, -7.2100e-01,  6.9294e-01,  9.6030e-01,\n",
      "         -2.7898e-01, -6.0833e-01,  7.9368e-01, -6.8375e-01, -7.2972e-01,\n",
      "          4.3251e-01, -9.0163e-01,  9.5732e-01, -2.8903e-01,  9.6072e-01,\n",
      "          2.7752e-01,  7.7844e-01,  6.2772e-01,  5.7878e-01,  8.1548e-01,\n",
      "          4.1416e-01,  9.1020e-01,  2.9115e-01,  9.5668e-01,  2.0296e-01,\n",
      "          9.7919e-01,  1.4093e-01,  9.9002e-01,  9.7669e-02,  9.9522e-01,\n",
      "          6.7627e-02,  9.9771e-01,  4.6805e-02,  9.9890e-01,  3.2387e-02,\n",
      "          9.9948e-01,  2.2408e-02,  9.9975e-01,  1.5504e-02,  9.9988e-01,\n",
      "          1.0726e-02,  9.9994e-01,  7.4207e-03,  9.9997e-01,  5.1339e-03,\n",
      "          9.9999e-01,  3.5518e-03,  9.9999e-01,  2.4572e-03,  1.0000e+00],\n",
      "        [-7.5099e-01,  6.6032e-01, -1.1317e-01,  9.9358e-01,  7.2390e-01,\n",
      "         -6.8991e-01, -3.1725e-01,  9.4834e-01, -8.3159e-01, -5.5539e-01,\n",
      "          2.8479e-01, -9.5859e-01,  9.1994e-01, -3.9206e-01,  9.7899e-01,\n",
      "          2.0392e-01,  8.1029e-01,  5.8602e-01,  6.0800e-01,  7.9394e-01,\n",
      "          4.3689e-01,  8.9951e-01,  3.0773e-01,  9.5147e-01,  2.1472e-01,\n",
      "          9.7668e-01,  1.4916e-01,  9.8881e-01,  1.0339e-01,  9.9464e-01,\n",
      "          7.1598e-02,  9.9743e-01,  4.9556e-02,  9.9877e-01,  3.4292e-02,\n",
      "          9.9941e-01,  2.3726e-02,  9.9972e-01,  1.6415e-02,  9.9987e-01,\n",
      "          1.1357e-02,  9.9994e-01,  7.8572e-03,  9.9997e-01,  5.4359e-03,\n",
      "          9.9999e-01,  3.7607e-03,  9.9999e-01,  2.6018e-03,  1.0000e+00],\n",
      "        [ 1.4988e-01,  9.8870e-01,  5.4670e-01,  8.3733e-01,  3.2481e-01,\n",
      "         -9.4578e-01,  8.3061e-03,  9.9997e-01, -9.3599e-01, -3.5203e-01,\n",
      "          1.2993e-01, -9.9152e-01,  8.7152e-01, -4.9037e-01,  9.9163e-01,\n",
      "          1.2914e-01,  8.3992e-01,  5.4271e-01,  6.3642e-01,  7.7134e-01,\n",
      "          4.5935e-01,  8.8826e-01,  3.2422e-01,  9.4598e-01,  2.2645e-01,\n",
      "          9.7402e-01,  1.5738e-01,  9.8754e-01,  1.0912e-01,  9.9403e-01,\n",
      "          7.5568e-02,  9.9714e-01,  5.2306e-02,  9.9863e-01,  3.6196e-02,\n",
      "          9.9934e-01,  2.5044e-02,  9.9969e-01,  1.7327e-02,  9.9985e-01,\n",
      "          1.1988e-02,  9.9993e-01,  8.2937e-03,  9.9997e-01,  5.7379e-03,\n",
      "          9.9998e-01,  3.9697e-03,  9.9999e-01,  2.7463e-03,  1.0000e+00]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "T_pos_encoding = get_positional_encoding(20, 50)\n",
    "print(T_pos_encoding.shape)\n",
    "print(T_pos_encoding)\n",
    "\n",
    "plt.pcolormesh(T_pos_encoding, cmap='RdBu')\n",
    "plt.xlabel('d')\n",
    "plt.xlim((0, 50))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1a54abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n",
      "tensor([[False,  True,  True,  True],\n",
      "        [False, False,  True,  True],\n",
      "        [False, False, False,  True],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_padding_mask(seq):\n",
    "    \"\"\"Create padding mask: True for padding positions\"\"\"\n",
    "    return seq == PAD_ID\n",
    "def create_look_ahead_mask(size):\n",
    "    \"\"\"Create look_ahead mask for decoder\"\"\"\n",
    "    mask = torch.triu(torch.ones(size, size,), diagonal=1)\n",
    "    return mask.bool()\n",
    "l=create_look_ahead_mask(4)\n",
    "print(l.shape)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bdc20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
    "        super()._init_()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_len, d_model = x.size()\n",
    "        x = x.view(batch_size, seq_len, self.num_heads, self.d_k)\n",
    "        return x.transpose(1, 2)\n",
    "    \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "        output = torch.matmul(attention_weights, V)\n",
    "        return output, attention_weights\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "        Q = self.split_heads(self.W_q(query))\n",
    "        K = self.split_heads(self.W_k(key))\n",
    "        V = self.split_heads(self.W_v(value))\n",
    "        attn_output, _ = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous()\n",
    "        attn_output = attn_output.view(batch_size, -1, self.d_model)\n",
    "        output = self.W_o(attn_output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2057a123",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def FullyConnected(embedding_dim,fully_connected_dim,dropout=0.1):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(embedding_dim,fully_connected_dim),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(fully_connected_dim,embedding_dim)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738a3bc0",
   "metadata": {},
   "source": [
    "<center><img src=\"img/encoder_layer.png\" alt=\"Encoder\" width=\"400\"/></center>\n",
    "\n",
    "<center><caption><b>Transformer encoder layer</caption></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2ed66fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self,embedding_dim,num_heads,ffn_dim,dropout_rate=0.1,layernorm_eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.mha=nn.MultiheadAttention(embed_dim=embedding_dim,num_heads=num_heads,dropout=dropout_rate,batch_first=True)\n",
    "        self.ffn=FullyConnected(embedding_dim,ffn_dim)\n",
    "        self.layernorm1=nn.LayerNorm(embedding_dim,eps=layernorm_eps)\n",
    "        self.layernorm2=nn.LayerNorm(embedding_dim,eps=layernorm_eps)\n",
    "        self.dropout_attn = nn.Dropout(dropout_rate)\n",
    "        self.dropout_ffn=nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self,x, mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the Encoder Layer    \n",
    "        Arguments:\n",
    "            x -- Tensor of shape (batch_size, input_seq_len, embedding_dim)\n",
    "            mask -- Boolean mask to ensure that the padding is not \n",
    "                    treated as part of the input\n",
    "        Returns:\n",
    "            encoder_layer_out -- Tensor of shape (batch_size, input_seq_len, embedding_dim)\n",
    "        \"\"\"\n",
    "        attn_output,_=self.mha(query=x,value=x,key=x,key_padding_mask=mask)# (batch_size, input_seq_len, embedding_dim)\n",
    "        attn_output = self.dropout_attn(attn_output)\n",
    "        skip_x_attn=self.layernorm1(x+attn_output)\n",
    "\n",
    "        ffn_output=self.ffn(skip_x_attn)\n",
    "        ffn_output=self.dropout_ffn(ffn_output)\n",
    "\n",
    "        out=self.layernorm2(ffn_output+skip_x_attn)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6acfc0",
   "metadata": {},
   "source": [
    "<center><img src=\"img/encoder.png\" alt=\"Encoder\" width=\"400\"/></center>\n",
    "\n",
    "<center><caption><b>Full encoder</caption></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4466e58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,num_layers, embedding_dim, num_heads, ffn_dim, input_vocab_size,max_seq_len, dropout_rate=0.1, padding_id=0):\n",
    "        super().__init__()\n",
    "        self.embedding_dim=embedding_dim\n",
    "        self.num_layers=num_layers\n",
    "        self.embedding= nn.Embedding(input_vocab_size,embedding_dim,padding_idx=padding_id)\n",
    "        self.pos_encoding= get_positional_encoding(max_seq_len,embedding_dim)\n",
    "        \n",
    "        self.enc_layers=nn.ModuleList([\n",
    "            EncoderLayer(embedding_dim,num_heads,ffn_dim,dropout_rate) for _ in range(num_layers) \n",
    "        ])\n",
    "        self.dropout= nn.Dropout(dropout_rate)\n",
    "        self.scale_dm = torch.sqrt(torch.tensor(self.embedding_dim))\n",
    "    def forward(self,x,padding_mask):\n",
    "         \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor of shape (batch_size, input_seq_len)\n",
    "            mask: key padding mask of shape (batch_size, input_seq_len)\n",
    "        Returns:\n",
    "            output: Tensor of shape (batch_size, input_seq_len, embedding_dim)\n",
    "        \"\"\"\n",
    "         seq_len=x.shape[1]\n",
    "         x=self.embedding(x)*self.scale_dm\n",
    "         pos_enc=self.pos_encoding[:seq_len,:].to(x.device)\n",
    "         x=self.dropout(x+pos_enc)\n",
    "\n",
    "         for i in range(self.num_layers):\n",
    "             x=self.enc_layers[i](x,padding_mask)\n",
    "        \n",
    "         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3442a0e5",
   "metadata": {},
   "source": [
    "<center><img src=\"img/decoder_layer.png\"  width=\"300\"/></center>\n",
    "\n",
    "<center><caption><b>Transformer decoder layer</caption></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db459240",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self,embedding_dim,num_heads,ffn_dim,dropout_rate=0.1,layernorm_eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.mha1=nn.MultiheadAttention(embedding_dim,num_heads,dropout=dropout_rate,batch_first=True)\n",
    "        self.mha2=nn.MultiheadAttention(embedding_dim,num_heads,dropout=dropout_rate,batch_first=True)\n",
    "        self.ffn=FullyConnected(embedding_dim,ffn_dim)\n",
    "        \n",
    "        self.layernorm1=nn.LayerNorm(embedding_dim,eps=layernorm_eps)\n",
    "        self.layernorm2=nn.LayerNorm(embedding_dim,eps=layernorm_eps)\n",
    "        self.layernorm3=nn.LayerNorm(embedding_dim,eps=layernorm_eps)\n",
    "\n",
    "        self.dropout1=nn.Dropout(dropout_rate)\n",
    "        self.dropout2=nn.Dropout(dropout_rate)\n",
    "        self.dropout3=nn.Dropout(dropout_rate)\n",
    "    def forward(self,x,enc_out,look_ahead_mask,padding_mask):\n",
    "        \n",
    "        masked_att,_=self.mha1(query=x,key=x,value=x,attn_mask=look_ahead_mask)\n",
    "        out1 = self.layernorm1( x + self.dropout1(masked_att))\n",
    "\n",
    "        cross_att,_=self.mha2(query=out1,key=enc_out,value=enc_out,key_padding_mask=padding_mask)\n",
    "        out2=self.layernorm2(out1+self.dropout2(cross_att))\n",
    "\n",
    "        ffn_out=self.ffn(out2)\n",
    "        out3=self.layernorm3(out2+self.dropout3(ffn_out))\n",
    "\n",
    "        return out3\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf9a705",
   "metadata": {},
   "source": [
    "<center><img src=\"img/decoder.png\"  width=\"300\"/></center>\n",
    "\n",
    "<center><caption><b>Full decoder</caption></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01ace956",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,num_layers,embedding_dim,num_heads,ffn_dim,target_vocab_size,max_seq_len,dropout_rate=0.1, padding_id=0):\n",
    "        super().__init__()\n",
    "        self.num_layers=num_layers\n",
    "        self.embedding_dim=embedding_dim\n",
    "        self.embedding=nn.Embedding(target_vocab_size,embedding_dim,padding_idx=padding_id)\n",
    "        self.pos_encoding=get_positional_encoding(max_seq_len,embedding_dim)\n",
    "        self.dec_layers=nn.ModuleList([\n",
    "            DecoderLayer(embedding_dim,num_heads,ffn_dim,dropout_rate) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.dropout=nn.Dropout(dropout_rate)\n",
    "        self.scale_dm = torch.sqrt(torch.tensor(self.embedding_dim))\n",
    "    def forward(self,x, enc_output,look_ahead_mask, padding_mask):\n",
    "        \"\"\"\n",
    "        Forward  pass for the Decoder\n",
    "        \n",
    "        Arguments:\n",
    "            x -- Tensor of shape (batch_size, target_seq_len)\n",
    "            enc_output --  Tensor of shape(batch_size, input_seq_len, embedding_dim)\n",
    "            look_ahead_mask -- Boolean mask for the target_input (batch_size, tgt_seq_len, tgt_seq_len)\n",
    "            padding_mask -- Boolean mask for the second multihead attention layer (batch_size, src_seq_len)\n",
    "        Returns:\n",
    "            x -- Tensor of shape (batch_size, target_seq_len, embedding_dim)\n",
    "        \"\"\"\n",
    "        seq_len=x.shape[1]\n",
    "        x=self.embedding(x)* self.scale_dm\n",
    "        pos_enc=self.pos_encoding[:seq_len,:].to(x.device)\n",
    "        x=self.dropout(x+pos_enc)\n",
    "        for i in range(self.num_layers):\n",
    "            x= self.dec_layers[i](x,enc_output,look_ahead_mask,padding_mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b447b5e7",
   "metadata": {},
   "source": [
    "<center><img src=\"img/transformer.png\"  width=\"400\"/></center>\n",
    "\n",
    "<center><caption><b>Full decoder</caption></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,vocab_size=256,max_seq_len=100,padding_idx=0):\n",
    "        super().__init__()\n",
    "        self.encoder=Encoder(num_layers=2,embedding_dim=256,num_heads=4,ffn_dim=1024,input_vocab_size=vocab_size,max_seq_len=max_seq_len,padding_id=padding_idx)\n",
    "        self.decoder=Decoder(num_layers=2,embedding_dim=256,num_heads=4,ffn_dim=1024,target_vocab_size=vocab_size,max_seq_len=max_seq_len,padding_id=padding_idx)\n",
    "        self.final_layer=nn.Linear(in_features=256,out_features=vocab_size)\n",
    "\n",
    "    def forward(self,src,tgt,padding_mask,tgt_look_ahead_mask,teacher_forcing=0):\n",
    "\n",
    "        batch_len,tgt_len = tgt.shape\n",
    "        dec_input= tgt[:,0:1]\n",
    "\n",
    "        enc_output =self.encoder(src,padding_mask)    \n",
    "\n",
    "        outputs=[]\n",
    "        for i in range(0,tgt_len):\n",
    "            \n",
    "            tgt_look_ahead_mask =create_look_ahead_mask(dec_input.size(1))\n",
    "            dec_out=self.decoder(dec_input,enc_output,tgt_look_ahead_mask,padding_mask)\n",
    "            pred=self.final_layer(dec_out)\n",
    "\n",
    "            outputs.append(pred[:,-1:,:])\n",
    "\n",
    "            if i<tgt_len-1:\n",
    "\n",
    "                tf=torch.rand(batch_len,1)<teacher_forcing\n",
    "                pred_t= pred[:,-1:,:].argmax(dim=-1)\n",
    "                ground_t=tgt[:,i+1:i+2]\n",
    "                next_t=torch.where(tf,ground_t,pred_t)\n",
    "\n",
    "                dec_input= torch.cat([dec_input,next_t],dim=1)\n",
    "\n",
    "        output=torch.cat(outputs,dim=1)\n",
    "        return output\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ee15ac",
   "metadata": {},
   "source": [
    "# --------------------TRAINING-TEST CODE--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e46bf0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,dataloader,criterian,optimizer,teacher_forcing=1.0):\n",
    "    model.train()\n",
    "    total_loss=0\n",
    "\n",
    "    progress_bar=tqdm(dataloader,desc=f\"Training (TF={teacher_forcing})\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch['input_ids']\n",
    "        target_ids = batch['target_ids']\n",
    "\n",
    "        decoder_input = target_ids[:, :-1]\n",
    "        decoder_target = target_ids[:, 1:]\n",
    "                \n",
    "        padding_mask=create_padding_mask(input_ids)\n",
    "        tgt_look_ahead_mask=create_look_ahead_mask(decoder_input.size(1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output= model(input_ids,decoder_input,padding_mask,tgt_look_ahead_mask,teacher_forcing=teacher_forcing)\n",
    "\n",
    "\n",
    "        loss = criterian(output.reshape(-1,output.size(-1)),decoder_target.reshape(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(),1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'Train loss': loss.item()})\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8399697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(predictions, references):\n",
    "    \"\"\"Calculate BLEU score\"\"\"\n",
    "    bleu = BLEU()\n",
    "    score = bleu.corpus_score(predictions, [references])\n",
    "    return score.score\n",
    "\n",
    "def calculate_rouge_l(predictions, references):\n",
    "    \"\"\"Calculate ROUGE-L score\"\"\"\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=False)\n",
    "    scores = []\n",
    "    for pred, ref in zip(predictions, references):\n",
    "        score = scorer.score(ref, pred)\n",
    "        scores.append(score['rougeL'].fmeasure)\n",
    "    return np.mean(scores) * 100\n",
    "\n",
    "def calculate_chrf(predictions, references):\n",
    "    \"\"\"Calculate chrF score\"\"\"\n",
    "    chrf = CHRF()\n",
    "    score = chrf.corpus_score(predictions, [references])\n",
    "    return score.score\n",
    "\n",
    "def calculate_perplexity(loss):\n",
    "    \"\"\"Calculate perplexity from loss\"\"\"\n",
    "    return math.exp(min(loss, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5dfe0845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterian):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(dataloader, desc=\"Evaluating (no teacher forcing)\")\n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch['input_ids']\n",
    "            target_ids = batch['target_ids']\n",
    "\n",
    "            decoder_input = target_ids[:, :-1]\n",
    "            decoder_target = target_ids[:, 1:]\n",
    "\n",
    "            padding_mask = create_padding_mask(input_ids)\n",
    "            tgt_look_ahead_mask = create_look_ahead_mask(decoder_input.size(1))\n",
    "\n",
    "            output = model(input_ids, decoder_input, padding_mask, tgt_look_ahead_mask, teacher_forcing=0)\n",
    "            loss = criterian(output.reshape(-1, output.size(-1)), decoder_target.reshape(-1))\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({'val loss': loss.item()})\n",
    "\n",
    "            # Decode predictions and references for metrics\n",
    "            pred_ids = output.argmax(dim=-1).cpu().tolist()\n",
    "            tgt_ids = decoder_target.cpu().tolist()\n",
    "            for pred, ref in zip(pred_ids, tgt_ids):\n",
    "                pred_text = tokenizer.decode(pred)\n",
    "                ref_text = tokenizer.decode(ref)\n",
    "                predictions.append(pred_text)\n",
    "                references.append(ref_text)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "    bleu_score = calculate_bleu(predictions, references)\n",
    "    rouge_score = calculate_rouge_l(predictions, references)\n",
    "    chrf_score = calculate_chrf(predictions, references)\n",
    "    perplexity = calculate_perplexity(avg_loss)\n",
    "\n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    print(\"  Val Loss: \",avg_loss)\n",
    "    print(\"  BLEU: \",bleu_score)\n",
    "    print(\"  ROUGE-L: \",rouge_score)\n",
    "    print(\"  chrF: \",chrf_score)\n",
    "    print(\"  Perplexity: \",perplexity)\n",
    "\n",
    "\n",
    "    return {\n",
    "        'predictions': predictions[:10],\n",
    "        'references': references[:10]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a57f71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 3,883,264\n"
     ]
    }
   ],
   "source": [
    "model=Transformer(vocab_size=VOCAB_SIZE,padding_idx=PAD_ID)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f94b60e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterian=nn.CrossEntropyLoss(ignore_index=PAD_ID)\n",
    "optimizer =torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "scheduler =torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=3,factor=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f94c9ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (TF=0.6):   2%|         | 6/257 [00:11<07:46,  1.86s/it, Train loss=3.83]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m loss =\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterian\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mteacher_forcing\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.6\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, dataloader, criterian, optimizer, teacher_forcing)\u001b[39m\n\u001b[32m     18\u001b[39m output= model(input_ids,decoder_input,padding_mask,tgt_look_ahead_mask,teacher_forcing=teacher_forcing)\n\u001b[32m     21\u001b[39m loss = criterian(output.reshape(-\u001b[32m1\u001b[39m,output.size(-\u001b[32m1\u001b[39m)),decoder_target.reshape(-\u001b[32m1\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(),\u001b[32m1.0\u001b[39m)\n\u001b[32m     24\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NCS\\anaconda3\\envs\\env_ML_2\\Lib\\site-packages\\torch\\_tensor.py:617\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    573\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Computes the gradient of current tensor wrt graph leaves.\u001b[39;00m\n\u001b[32m    574\u001b[39m \n\u001b[32m    575\u001b[39m \u001b[33;03mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    614\u001b[39m \u001b[33;03m        used to compute the :attr:`tensors`.\u001b[39;00m\n\u001b[32m    615\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m        \u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    626\u001b[39m torch.autograd.backward(\n\u001b[32m    627\u001b[39m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs=inputs\n\u001b[32m    628\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NCS\\anaconda3\\envs\\env_ML_2\\Lib\\site-packages\\torch\\overrides.py:1720\u001b[39m, in \u001b[36mhandle_torch_function\u001b[39m\u001b[34m(public_api, relevant_args, *args, **kwargs)\u001b[39m\n\u001b[32m   1716\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[32m   1717\u001b[39m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[32m   1718\u001b[39m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[32m   1719\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[32m-> \u001b[39m\u001b[32m1720\u001b[39m         result = \u001b[43mmode\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1721\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[32m   1722\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NCS\\anaconda3\\envs\\env_ML_2\\Lib\\site-packages\\torch\\utils\\_device.py:104\u001b[39m, in \u001b[36mDeviceContext.__torch_function__\u001b[39m\u001b[34m(self, func, types, args, kwargs)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs.get(\u001b[33m'\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    103\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m.device\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NCS\\anaconda3\\envs\\env_ML_2\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NCS\\anaconda3\\envs\\env_ML_2\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NCS\\anaconda3\\envs\\env_ML_2\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "loss =train_epoch(model,train_loader,criterian,optimizer,teacher_forcing=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3611f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (no teacher forcing): 100%|| 65/65 [00:35<00:00,  1.85it/s, val loss=3.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results:\n",
      "  Val Loss:  3.6324480790358322\n",
      "  BLEU:  0.0\n",
      "  ROUGE-L:  83.48919860627177\n",
      "  chrF:  30.289035775341734\n",
      "  Perplexity:  37.805253673368846\n"
     ]
    }
   ],
   "source": [
    "output = evaluate(model, val_loader,criterian)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ce06113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "\n",
      "  Example 1:\n",
      "    Prediction: <mask>\n",
      "    Reference:  <mask><mask><mask><mask>\n",
      "\n",
      "  Example 2:\n",
      "    Prediction: <mask>\n",
      "    Reference:  <mask>\n",
      "\n",
      "  Example 3:\n",
      "    Prediction: <mask>\n",
      "    Reference:  <mask> \n",
      "\n",
      "  Example 4:\n",
      "    Prediction: <mask>\n",
      "    Reference:  <mask>   \n",
      "\n",
      "  Example 5:\n",
      "    Prediction: <mask>\n",
      "    Reference:  <mask> \n",
      "\n",
      "  Example 6:\n",
      "    Prediction: <mask>\n",
      "    Reference:  <mask><mask><mask>\n",
      "\n",
      "  Example 7:\n",
      "    Prediction: <mask>\n",
      "    Reference:  <mask><mask> <mask>  \n",
      "\n",
      "  Example 8:\n",
      "    Prediction: <mask>\n",
      "    Reference:  <mask>\n",
      "\n",
      "  Example 9:\n",
      "    Prediction: <mask>\n",
      "    Reference:  <mask>   <mask>\n",
      "\n",
      "  Example 10:\n",
      "    Prediction: <mask>\n",
      "    Reference:  <mask> \n"
     ]
    }
   ],
   "source": [
    "print(\"Examples:\")\n",
    "for i in range(10):\n",
    "    print(f\"\\n  Example {i+1}:\")\n",
    "    print(f\"    Prediction: {output['predictions'][i]}\")\n",
    "    print(f\"    Reference:  {output['references'][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22319598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ML_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
